{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting notebook for the project\n",
    "# Imports\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "from datetime import datetime\n",
    "import scipy.stats as stats\n",
    "\n",
    "# import cdo\n",
    "from cdo import *\n",
    "cdo = Cdo()\n",
    "\n",
    "# Local imports\n",
    "sys.path.append('/home/users/benhutch/skill-maps-historical')\n",
    "import dictionaries as dic\n",
    "import functions as fnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the parameters again\n",
    "# for the years 2-9 psl ULG (JJA)\n",
    "var = \"psl\"\n",
    "region = \"global\"\n",
    "region_grid = dic.gridspec_global\n",
    "forecast_range = \"2-9\"\n",
    "season = \"DJFM\" # weird season name for model\n",
    "observations_path = dic.obs\n",
    "obs_var_name = \"psl\"\n",
    "model_dict = dic.model_dictionary_psl_historical_badc\n",
    "start_year = 1960\n",
    "end_year = 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process the observations first of all\n",
    "# obs = fnc.process_observations(var, region, region_grid,\n",
    "#                                forecast_range, season, observations_path,\n",
    "#                                obs_var_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing model:  BCC-CSM2-MR\n",
      "runs for model  BCC-CSM2-MR :  [1, 2, 3]\n",
      "processing run:  1\n",
      "processing init scheme:  1\n",
      "dir_path:  /badc/cmip6/data/CMIP6/CMIP/*/BCC-CSM2-MR/historical/r1i1p[1]f[1]/Amon/psl/g?/files/d????????/\n",
      "Error, merged file does not exist:  /gws/nopw/j04/canari/users/benhutch/historical/psl/BCC-CSM2-MR/mergetime/psl_Amon_BCC-CSM2-MR_historical_r1i1p[1]f[1]_g?_*.nc\n",
      "Error, regridded file does not exist\n"
     ]
    }
   ],
   "source": [
    "# First we want to merge the time axis and regrid the model (historical) data\n",
    "# using the function call_mergetime_regrid\n",
    "# this does not return anything, but saves the regridded data to a netcdf file\n",
    "fnc.call_mergetime_regrid(model_dict, var, region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing model:  BCC-CSM2-MR\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"dict\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Now we want to load the historical data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# as a dictionary of xarray datasets for each model\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# using the load_historical_data function\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m historical_data \u001b[38;5;241m=\u001b[39m \u001b[43mfnc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_historical_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregion\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/skill-maps-historical/functions.py:360\u001b[0m, in \u001b[0;36mload_historical_data\u001b[0;34m(model_dict, var, region)\u001b[0m\n\u001b[1;32m    355\u001b[0m member_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# Set up the directory path\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# Where all of the members (each unique r?i?p?f? combination) are stored\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# We want the regridded files\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m regrid_files \u001b[38;5;241m=\u001b[39m \u001b[43mdic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanari_base_path_historical\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/regrid\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m var \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAmon\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m model \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistorical\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr?i?p?f?\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m region \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_regrid.nc\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;66;03m# Check that the regrid files exist\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(glob\u001b[38;5;241m.\u001b[39mglob(regrid_files)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"dict\") to str"
     ]
    }
   ],
   "source": [
    "# Now we want to load the historical data\n",
    "# as a dictionary of xarray datasets for each model\n",
    "# using the load_historical_data function\n",
    "historical_data = fnc.load_historical_data(model_dict, var, region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we want to call the function to process the historical data\n",
    "# this will:\n",
    "# 1. constrain the data to the provided year range and season\n",
    "# 2. calculate the climatology and remove this to create anomalies\n",
    "# 3. calculate the annual mean anomalies from the monthly mean anomalies\n",
    "# 4. calculate the running mean of these annual mean anomalies\n",
    "# then add the processed data back into the dictionary\n",
    "historical_data = fnc.process_historical_data(historical_data, season, forecast_range, start_year, end_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to process the historical data\n",
    "# in preperation for calculating the spatial correlations\n",
    "# this function constrains the years to only those available in all members\n",
    "# and then calculates the equally weighted ensemble mean of all members\n",
    "# using the function process_historical_data_spacial_correlations\n",
    "ensemble_mean = fnc.process_historical_data_spatial_correlations(historical_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bens-python-environment",
   "language": "python",
   "name": "bens-python-environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
