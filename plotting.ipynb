{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting notebook for the project\n",
    "# Imports\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# Third-party imports # test\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "from datetime import datetime\n",
    "import scipy.stats as stats\n",
    "import dask.array as da\n",
    "import dask\n",
    "import dask.distributed as dd\n",
    "\n",
    "# Import dask gateway\n",
    "import dask_gateway\n",
    "\n",
    "# import cdo\n",
    "from cdo import *\n",
    "cdo = Cdo()\n",
    "\n",
    "# Local imports\n",
    "sys.path.append('/home/users/benhutch/skill-maps-historical')\n",
    "import dictionaries as dic\n",
    "import functions as fnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the parameters again\n",
    "# for the years 2-9 psl ULG (JJA)\n",
    "var = \"psl\"\n",
    "region = \"global\"\n",
    "region_grid = dic.gridspec_global\n",
    "forecast_range = \"2-9\"\n",
    "season = \"DJFM\" # weird season name for model\n",
    "observations_path = dic.obs\n",
    "obs_var_name = \"psl\"\n",
    "model_dict = dic.model_dictionary_psl_historical_badc\n",
    "start_year = 1960\n",
    "end_year = 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process the observations first of all\n",
    "# obs = fnc.process_observations(var, region, region_grid,\n",
    "#                                forecast_range, season, observations_path,\n",
    "#                                obs_var_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First we want to merge the time axis and regrid the model (historical) data\n",
    "# # using the function call_mergetime_regrid\n",
    "# # this does not return anything, but saves the regridded data to a netcdf file\n",
    "# fnc.call_mergetime_regrid(model_dict, var, region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing model:  BCC-CSM2-MR\n",
      "type of var <class 'str'>\n",
      "type of model <class 'str'>\n",
      "type of region <class 'str'>\n",
      "regrid_files: /gws/nopw/j04/canari/users/benhutch/historical/psl/BCC-CSM2-MR/regrid/psl_Amon_BCC-CSM2-MR_historical_r*i?p?f?_*global_regrid.nc\n",
      "number of files for model  BCC-CSM2-MR :  3\n",
      "processing model:  MPI-ESM1-2-HR\n",
      "type of var <class 'str'>\n",
      "type of model <class 'str'>\n",
      "type of region <class 'str'>\n",
      "regrid_files: /gws/nopw/j04/canari/users/benhutch/historical/psl/MPI-ESM1-2-HR/regrid/psl_Amon_MPI-ESM1-2-HR_historical_r*i?p?f?_*global_regrid.nc\n",
      "number of files for model  MPI-ESM1-2-HR :  1\n",
      "processing model:  CanESM5\n",
      "type of var <class 'str'>\n",
      "type of model <class 'str'>\n",
      "type of region <class 'str'>\n",
      "regrid_files: /gws/nopw/j04/canari/users/benhutch/historical/psl/CanESM5/regrid/psl_Amon_CanESM5_historical_r*i?p?f?_*global_regrid.nc\n",
      "number of files for model  CanESM5 :  35\n",
      "processing model:  CMCC-CM2-SR5\n",
      "type of var <class 'str'>\n",
      "type of model <class 'str'>\n",
      "type of region <class 'str'>\n",
      "regrid_files: /gws/nopw/j04/canari/users/benhutch/historical/psl/CMCC-CM2-SR5/regrid/psl_Amon_CMCC-CM2-SR5_historical_r*i?p?f?_*global_regrid.nc\n",
      "number of files for model  CMCC-CM2-SR5 :  1\n",
      "processing model:  HadGEM3-GC31-MM\n",
      "type of var <class 'str'>\n",
      "type of model <class 'str'>\n",
      "type of region <class 'str'>\n",
      "regrid_files: /gws/nopw/j04/canari/users/benhutch/historical/psl/HadGEM3-GC31-MM/regrid/psl_Amon_HadGEM3-GC31-MM_historical_r*i?p?f?_*global_regrid.nc\n",
      "number of files for model  HadGEM3-GC31-MM :  4\n",
      "processing model:  EC-Earth3\n",
      "type of var <class 'str'>\n",
      "type of model <class 'str'>\n",
      "type of region <class 'str'>\n",
      "regrid_files: /gws/nopw/j04/canari/users/benhutch/historical/psl/EC-Earth3/regrid/psl_Amon_EC-Earth3_historical_r*i?p?f?_*global_regrid.nc\n",
      "number of files for model  EC-Earth3 :  50\n",
      "processing model:  MPI-ESM1-2-LR\n",
      "type of var <class 'str'>\n",
      "type of model <class 'str'>\n",
      "type of region <class 'str'>\n",
      "regrid_files: /gws/nopw/j04/canari/users/benhutch/historical/psl/MPI-ESM1-2-LR/regrid/psl_Amon_MPI-ESM1-2-LR_historical_r*i?p?f?_*global_regrid.nc\n",
      "number of files for model  MPI-ESM1-2-LR :  1\n",
      "processing model:  FGOALS-f3-L\n",
      "type of var <class 'str'>\n",
      "type of model <class 'str'>\n",
      "type of region <class 'str'>\n",
      "regrid_files: /gws/nopw/j04/canari/users/benhutch/historical/psl/FGOALS-f3-L/regrid/psl_Amon_FGOALS-f3-L_historical_r*i?p?f?_*global_regrid.nc\n",
      "number of files for model  FGOALS-f3-L :  1\n",
      "processing model:  MIROC6\n",
      "type of var <class 'str'>\n",
      "type of model <class 'str'>\n",
      "type of region <class 'str'>\n",
      "regrid_files: /gws/nopw/j04/canari/users/benhutch/historical/psl/MIROC6/regrid/psl_Amon_MIROC6_historical_r*i?p?f?_*global_regrid.nc\n",
      "number of files for model  MIROC6 :  50\n",
      "processing model:  IPSL-CM6A-LR\n",
      "type of var <class 'str'>\n",
      "type of model <class 'str'>\n",
      "type of region <class 'str'>\n",
      "regrid_files: /gws/nopw/j04/canari/users/benhutch/historical/psl/IPSL-CM6A-LR/regrid/psl_Amon_IPSL-CM6A-LR_historical_r*i?p?f?_*global_regrid.nc\n",
      "number of files for model  IPSL-CM6A-LR :  9\n",
      "processing model:  NorCPM1\n",
      "type of var <class 'str'>\n",
      "type of model <class 'str'>\n",
      "type of region <class 'str'>\n",
      "regrid_files: /gws/nopw/j04/canari/users/benhutch/historical/psl/NorCPM1/regrid/psl_Amon_NorCPM1_historical_r*i?p?f?_*global_regrid.nc\n",
      "number of files for model  NorCPM1 :  1\n",
      "type of historical_data <class 'dict'>\n",
      "shape of historical_data ()\n"
     ]
    }
   ],
   "source": [
    "# Now we want to load the historical data\n",
    "# as a dictionary of xarray datasets for each model\n",
    "# using the load_historical_data function\n",
    "historical_data = fnc.load_historical_data(model_dict, var, region)\n",
    "\n",
    "# historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing model:  BCC-CSM2-MR\n",
      "processing member:  0\n",
      "processing member:  1\n",
      "processing member:  2\n"
     ]
    }
   ],
   "source": [
    "# test = historical_data['NorCPM1'][0].psl\n",
    "\n",
    "# # # test the processing functions individually\n",
    "# constrained_data = fnc.constrain_historical_data_season(historical_data, start_year=1960, end_year=2019\n",
    "#                                                         , season='DJFM', model='NorCPM1',member=0)\n",
    "\n",
    "# constrained_data\n",
    "\n",
    "# test the processing functions individually\n",
    "# test_BCC = historical_data['BCC-CSM2-MR']\n",
    "\n",
    "# # test the processing historical data function\n",
    "processed_test_BCC = fnc.process_historical_data_dask(historical_data, season='DJFM', forecast_range='2-9', \n",
    "                                                start_year=1960, end_year=2019)\n",
    "\n",
    "# look at the processed data\n",
    "processed_test_BCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Look at the data we have processed\n",
    "# processed_test_BCC['BCC-CSM2-MR'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the ensemble mean\n",
    "import xarray as xr\n",
    "\n",
    "# Load the three datasets into a list\n",
    "datasets = [historical_data['BCC-CSM2-MR'][member] for member in historical_data['BCC-CSM2-MR']]\n",
    "\n",
    "# Combine the datasets into a single dataset along the 'member' dimension\n",
    "ensemble = xr.concat(datasets, dim='member')\n",
    "\n",
    "# Calculate the ensemble mean along the 'member' dimension\n",
    "ensemble_mean = ensemble.mean(dim='member')\n",
    "\n",
    "# Calculate the time mean along the 'time' dimension\n",
    "time_mean = ensemble_mean.mean(dim='time')\n",
    "\n",
    "time_mean.psl.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now call the parallel processing function\n",
    "processed_historical_data = fnc.process_historical_data_parallel(historical_data,\n",
    "                            season, forecast_range, start_year, end_year) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we want to call the function to process the historical data\n",
    "# this will: test\n",
    "# 1. constrain the data to the provided year range and season\n",
    "# 2. calculate the climatology and remove this to create anomalies\n",
    "# 3. calculate the annual mean anomalies from the monthly mean anomalies\n",
    "# 4. calculate the running mean of these annual mean anomalies\n",
    "# then add the processed data back into the dictionary\n",
    "processed_historical_data = fnc.process_historical_data(historical_data, season, forecast_range, start_year, end_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the processed data\n",
    "processed_historical_data['NorCPM1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to process the historical data\n",
    "# in preperation for calculating the spatial correlations\n",
    "# this function constrains the years to only those available in all members\n",
    "# and then calculates the equally weighted ensemble mean of all members\n",
    "# using the function process_historical_data_spacial_correlations\n",
    "ensemble_mean = fnc.process_historical_data_spatial_correlations(processed_historical_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
