{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting notebook for the project\n",
    "# Imports\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "from datetime import datetime\n",
    "import scipy.stats as stats\n",
    "\n",
    "# import cdo\n",
    "from cdo import *\n",
    "cdo = Cdo()\n",
    "\n",
    "# Local imports\n",
    "sys.path.append('/home/users/benhutch/skill-maps-historical')\n",
    "import dictionaries as dic\n",
    "import functions as fnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the parameters again\n",
    "# for the years 2-9 psl ULG (JJA)\n",
    "var = \"psl\"\n",
    "region = \"global\"\n",
    "region_grid = dic.gridspec_global\n",
    "forecast_range = \"2-9\"\n",
    "season = \"DJFM\" # weird season name for model\n",
    "observations_path = dic.obs\n",
    "obs_var_name = \"psl\"\n",
    "model_dict = dic.model_dictionary_psl_historical_badc\n",
    "start_year = 1960\n",
    "end_year = 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n",
      "Regridded and selected region dataset: <xarray.DataArray 'time' (time: 259)>\n",
      "array(['1959-01-01T00:00:00.000000000', '1959-02-01T00:00:00.000000000',\n",
      "       '1959-03-01T00:00:00.000000000', ..., '2023-01-01T00:00:00.000000000',\n",
      "       '2023-02-01T00:00:00.000000000', '2023-03-01T00:00:00.000000000'],\n",
      "      dtype='datetime64[ns]')\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1959-01-01 1959-02-01 ... 2023-03-01\n",
      "Attributes:\n",
      "    standard_name:  time\n",
      "    long_name:      time\n",
      "    axis:           T\n",
      "Forecast range: 2 - 9\n",
      "Rolling mean range: 8\n"
     ]
    }
   ],
   "source": [
    "# Process the observations first of all\n",
    "obs = fnc.process_observations(var, region, region_grid,\n",
    "                               forecast_range, season, observations_path,\n",
    "                               obs_var_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing model:  BCC-CSM2-MR\n",
      "runs for model  BCC-CSM2-MR :  [1, 2, 3]\n",
      "processing run:  1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'dictionaries' has no attribute 'base_path_example'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# First we want to merge the time axis and regrid the model (historical) data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# using the function call_mergetime_regrid\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# this does not return anything, but saves the regridded data to a netcdf file\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mfnc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_mergetime_regrid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregion\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/skill-maps-historical/functions.py:305\u001b[0m, in \u001b[0;36mcall_mergetime_regrid\u001b[0;34m(model_dict, var, region)\u001b[0m\n\u001b[1;32m    301\u001b[0m forcing_scheme \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforcing_scheme\u001b[39m\u001b[38;5;124m'\u001b[39m])]\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# Merge the time axis of the files\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# using the merge_time_axis function\u001b[39;00m\n\u001b[0;32m--> 305\u001b[0m merged_file \u001b[38;5;241m=\u001b[39m merge_time_axis(model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m], var, run, init_scheme, physics_scheme, forcing_scheme, \u001b[43mdic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_path_example\u001b[49m)\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# Check that the merged file exists\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merged_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'dictionaries' has no attribute 'base_path_example'"
     ]
    }
   ],
   "source": [
    "# First we want to merge the time axis and regrid the model (historical) data\n",
    "# using the function call_mergetime_regrid\n",
    "# this does not return anything, but saves the regridded data to a netcdf file\n",
    "fnc.call_mergetime_regrid(model_dict, var, region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to load the historical data\n",
    "# as a dictionary of xarray datasets for each model\n",
    "# using the load_historical_data function\n",
    "historical_data = fnc.load_historical_data(model_dict, var, region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we want to call the function to process the historical data\n",
    "# this will:\n",
    "# 1. constrain the data to the provided year range and season\n",
    "# 2. calculate the climatology and remove this to create anomalies\n",
    "# 3. calculate the annual mean anomalies from the monthly mean anomalies\n",
    "# 4. calculate the running mean of these annual mean anomalies\n",
    "# then add the processed data back into the dictionary\n",
    "historical_data = fnc.process_historical_data(historical_data, season, forecast_range, start_year, end_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to process the historical data\n",
    "# in preperation for calculating the spatial correlations\n",
    "# this function constrains the years to only those available in all members\n",
    "# and then calculates the equally weighted ensemble mean of all members\n",
    "# using the function process_historical_data_spacial_correlations\n",
    "ensemble_mean = fnc.process_historical_data_spatial_correlations(historical_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bens-python-environment",
   "language": "python",
   "name": "bens-python-environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
